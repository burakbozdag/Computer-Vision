{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip install vit_keras -q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from time import time\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "\n",
    "import tensorflow as tf\n",
    "from vit_keras import  vit, utils \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, \n",
    "    Activation, Add, multiply, add, concatenate, LeakyReLU, ZeroPadding2D, UpSampling2D, \n",
    "    BatchNormalization, SeparableConv2D, Flatten )\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = './chest_xray/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             validation_split=0.25,\n",
    "                             zoom_range=0.1,\n",
    "                             rotation_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def get_transforms(data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        IMG_TRAIN = MAIN_PATH +'train/'\n",
    "        train_generator = datagen.flow_from_directory(\n",
    "            # dataframe = train,\n",
    "            directory = IMG_TRAIN,\n",
    "            # x_col = 'filename',\n",
    "            # y_col = 'label',\n",
    "            batch_size  = 8,\n",
    "            shuffle=True,\n",
    "            class_mode = 'categorical',\n",
    "            target_size = (224, 224)\n",
    "        )\n",
    "\n",
    "        return train_generator\n",
    "\n",
    "    elif data == 'valid':\n",
    "        IMG_VAL = MAIN_PATH + 'val/'\n",
    "        valid_generator = datagen.flow_from_directory(\n",
    "            # dataframe = valid,\n",
    "            directory = IMG_VAL,\n",
    "            # x_col = 'filename',\n",
    "            # y_col = 'label',\n",
    "            batch_size = 8,\n",
    "            shuffle = True,\n",
    "            class_mode = 'categorical',\n",
    "            target_size = (224, 224)\n",
    "        )\n",
    "\n",
    "        return valid_generator\n",
    "\n",
    "    else :\n",
    "        IMG_TEST = MAIN_PATH + 'test/'\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            # dataframe = test,\n",
    "            directory = IMG_TEST,\n",
    "            # x_col = 'filename',\n",
    "            # y_col = None,\n",
    "            batch_size = 8,\n",
    "            shuffle = False,\n",
    "            class_mode = None,\n",
    "            target_size = (224, 224)\n",
    "        )\n",
    "\n",
    "        return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = get_transforms('train')\n",
    "valid = get_transforms('valid')\n",
    "test = get_transforms('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.25, patience=5, verbose=1, mode='auto',\n",
    "    min_delta=1e-10, cooldown=0, min_lr=0\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=9, verbose=1, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "ckpt = ModelCheckpoint(\n",
    "    filepath = './saved_model/checkpoint/',\n",
    "    save_weights_only = True,\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'min',\n",
    "    save_best_only = True\n",
    ")\n",
    "\n",
    "callbacks = [reduce_learning_rate, early_stopping, ckpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burak\\anaconda3\\lib\\site-packages\\vit_keras\\utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "model = vit.vit_b16(\n",
    "    image_size = image_size,\n",
    "    activation = 'softmax',\n",
    "    pretrained = True,\n",
    "    include_top = True,\n",
    "    pretrained_top = False,\n",
    "    classes = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown attribute 'DML' is encountered while parsing the device spec: '/DML:0'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:2024\u001b[0m, in \u001b[0;36m_EagerDeviceContext.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2023\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2024\u001b[0m   new_device_name, new_device_spec \u001b[38;5;241m=\u001b[39m \u001b[43m_device_parsing_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   2026\u001b[0m   \u001b[38;5;66;03m# Error while trying to compute the cache key.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('', '/DML:0')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physical_devices())\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/DML:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      3\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mvalid, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:2035\u001b[0m, in \u001b[0;36m_EagerDeviceContext.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_device_name, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2033\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting a string device name. Got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   2034\u001b[0m                    (\u001b[38;5;28mtype\u001b[39m(new_device_name), new_device_name))\n\u001b[1;32m-> 2035\u001b[0m device_spec \u001b[38;5;241m=\u001b[39m \u001b[43mpydev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeviceSpec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_device_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m old_device_name:\n\u001b[0;32m   2037\u001b[0m   new_device_spec \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(old_device_spec)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\device_spec.py:158\u001b[0m, in \u001b[0;36mDeviceSpecV2.from_string\u001b[1;34m(cls, spec)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_string\u001b[39m(\u001b[38;5;28mcls\u001b[39m, spec):\n\u001b[0;32m    147\u001b[0m   \u001b[38;5;124;03m\"\"\"Construct a `DeviceSpec` from a string.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    A DeviceSpec.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_string_to_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\device_spec.py:362\u001b[0m, in \u001b[0;36mDeviceSpecV2._string_to_components\u001b[1;34m(spec)\u001b[0m\n\u001b[0;32m    360\u001b[0m         device_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(y[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m ly \u001b[38;5;129;01mand\u001b[39;00m y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# pylint: disable=g-explicit-bool-comparison\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is encountered \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile parsing the device spec: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    365\u001b[0m output \u001b[38;5;241m=\u001b[39m (job, replica, task, device_type, device_index)\n\u001b[0;32m    366\u001b[0m _STRING_TO_COMPONENTS_CACHE[raw_spec] \u001b[38;5;241m=\u001b[39m output\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown attribute 'DML' is encountered while parsing the device spec: '/DML:0'."
     ]
    }
   ],
   "source": [
    "with tf.device(\"/DML:0\"):\n",
    "    history = model.fit(train, epochs=50, validation_data=valid, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test, verbose=1)\n",
    "y_pred = np.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df (dataset, label):\n",
    "    filenames = []  \n",
    "    labels = []\n",
    "    for file in os.listdir(MAIN_PATH + f'{dataset}/{label}'):\n",
    "        filenames.append(file)\n",
    "        labels.append(label)\n",
    "    return pd.DataFrame({'filename':filenames, 'label':labels})\n",
    "\n",
    "test_NORMAL = create_df('test', 'NORMAL')\n",
    "test_PNEUMONIA = create_df('test', 'PNEUMONIA')\n",
    "test_ori = test_NORMAL.append(test_PNEUMONIA, ignore_index=True)\n",
    "test_ori['label'] = test_ori['label'].apply(lambda x: 0 if x=='NORMAL' else 1)\n",
    "y_true = test_ori['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
